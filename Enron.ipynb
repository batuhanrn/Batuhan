{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import enchant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(list):\n",
    "    pattern = '[0-9]'\n",
    "    list = [re.sub(pattern, '', i) for i in list]\n",
    "    return list\n",
    "\n",
    "def remove_length(list):\n",
    "    for object in list:\n",
    "        if len(object) < 2:\n",
    "            list.remove(object)\n",
    "    return list\n",
    "\n",
    "def length_probs(list,count_normalizer,multipler,prob):\n",
    "    spam_length_probs = []\n",
    "    ham_length_probs = []\n",
    "    counter = 0\n",
    "    prob_spam = prob * multipler * count_normalizer\n",
    "    prob_ham = (1 - prob) * multipler\n",
    "    \n",
    "    for object in list:\n",
    "        if len(object)<2:\n",
    "            spam_length_probs.append(prob_spam)\n",
    "            ham_length_probs.append(prob_ham)\n",
    "            counter += 1\n",
    "        if counter > 6:\n",
    "            break\n",
    "        \n",
    "    return spam_length_probs, ham_length_probs\n",
    "\n",
    "def is_english_probs(list,count_normalizer,multipler,prob_not_eng,prob2):\n",
    "    spam_is_english_probs = []\n",
    "    ham_is_english_probs = []\n",
    "    \n",
    "    english_words = enchant.Dict(\"en_US\")\n",
    "    counter = 0\n",
    "    prob_spam = prob_not_eng * multipler * count_normalizer\n",
    "    prob_ham = (1 - prob_not_eng) * multipler\n",
    "    for object in list:\n",
    "        try:\n",
    "            if not english_words.check(object):\n",
    "                spam_is_english_probs.append(prob_spam)\n",
    "                ham_is_english_probs.append(prob_ham)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        counter += 1\n",
    "        if counter > 6:\n",
    "            break\n",
    "            \n",
    "    for object in list:\n",
    "        try:\n",
    "            if english_words.check(object):\n",
    "                spam_is_english_probs((1-prob2)*multipler*count_normalizer)\n",
    "                ham_is_english_probs((prob2)*multipler)\n",
    "        except:\n",
    "            pass\n",
    "        counter += 1\n",
    "        if counter > 10:\n",
    "            break\n",
    "            \n",
    "    return spam_is_english_probs, ham_is_english_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Based on Email List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_list(ham_file_location, spam_file_location):\n",
    "    \n",
    "    all_files_ham = os.listdir(ham_file_location)\n",
    "    ham_email_list = []\n",
    "    ham_list = []\n",
    "    ham_subject_list = []\n",
    "    ham_split_list = []\n",
    "    ham_subject_split_list = []\n",
    "    ham_all_split_list = []\n",
    "    ham_all = []\n",
    "    \n",
    "    for ham_email in all_files_ham:\n",
    "        try:\n",
    "            ham_email_txt = open(ham_file_location+\"/\" + ham_email).read()\n",
    "        except:\n",
    "            ham_email_txt = open(ham_file_location+\"/\" + ham_email,encoding='latin-1').read()\n",
    "        \n",
    "        ham_email_txt = ham_email_txt.replace('Subject: ','imzabatuhan928 ')\n",
    "        \n",
    "        for c in string.punctuation:\n",
    "            ham_email_txt = ham_email_txt.replace(c,'')\n",
    "\n",
    "        ham_email_txt = ham_email_txt.lower()\n",
    "        \n",
    "        subject_ham = re.findall(\"imzabatuhan928 (.*)\",ham_email_txt)[0]\n",
    "        \n",
    "        ham_subject_list.append(subject_ham)\n",
    "        ham_email_body = ham_email_txt.replace(\"imzabatuhan928\"+ re.findall(\"imzabatuhan928(.*)\"\\\n",
    "                                                                             ,ham_email_txt)[0],'')\n",
    "        ham_list.append(ham_email_body)\n",
    "        ham_email_list.append(ham_email)\n",
    "        \n",
    "        ham_email_txt_split = ham_email_body.split()\n",
    "        ham_email_txt_split = list(Counter(ham_email_txt_split).keys())\n",
    "        ham_split_list.append(ham_email_txt_split)\n",
    "        \n",
    "        subject_ham_split = subject_ham.split()\n",
    "        subject_ham_split = list(Counter(subject_ham_split).keys())\n",
    "        ham_subject_split_list.append(subject_ham_split)\n",
    "        \n",
    "                \n",
    "        ham_email_txt = ham_email_txt.replace('imzabatuhan928','')\n",
    "        ham_all.append(ham_email_txt)\n",
    "        \n",
    "        ham_email_split = ham_email_txt.split()\n",
    "        ham_all_split_list.append(ham_email_split)\n",
    "        \n",
    "    df_ham = pd.DataFrame()\n",
    "    df_ham['Email'] = ham_email_list\n",
    "    df_ham['Email_All'] = ham_all\n",
    "    df_ham['Email_All_Split'] = ham_all_split_list\n",
    "    df_ham['Email_Body'] = ham_list\n",
    "    df_ham['Email_Body_Split'] = ham_split_list\n",
    "    df_ham['Email_Subject'] = ham_subject_list\n",
    "    df_ham['Email_Subject_Split'] = ham_subject_split_list\n",
    "    \n",
    "    \n",
    "    df_ham['F_Spam'] = 0\n",
    "\n",
    "    \n",
    "    #---------------------------------------\n",
    "    \n",
    "    \n",
    "    all_files_spam = os.listdir(spam_file_location)\n",
    "    spam_email_list = []\n",
    "    spam_list = []\n",
    "    spam_subject_list = []\n",
    "    spam_split_list = []\n",
    "    spam_subject_split_list = []\n",
    "    spam_all_split_list = []\n",
    "    spam_all = []\n",
    "        \n",
    "    for spam_email in all_files_spam:\n",
    "        try:\n",
    "            spam_email_txt = open(spam_file_location+\"/\" + spam_email).read()\n",
    "        except:\n",
    "            spam_email_txt = open(spam_file_location+\"/\" + spam_email,encoding='latin-1').read()\n",
    "        \n",
    "        \n",
    "        spam_email_txt = spam_email_txt.replace('Subject: ','imzabatuhan928 ')\n",
    "        \n",
    "        for c in string.punctuation:\n",
    "            spam_email_txt = spam_email_txt.replace(c,'')\n",
    "         \n",
    "        spam_email_txt = spam_email_txt.lower()\n",
    "\n",
    "        subject_spam = re.findall(\"imzabatuhan928 (.*)\",spam_email_txt)[0]\n",
    "        \n",
    "        spam_subject_list.append(subject_spam)\n",
    "        spam_email_body = spam_email_txt.replace(\"imzabatuhan928\"+ re.findall(\"imzabatuhan928(.*)\"\\\n",
    "                                                                             ,spam_email_txt)[0],'')\n",
    "        \n",
    "\n",
    "        spam_list.append(spam_email_body)\n",
    "        spam_email_list.append(spam_email)\n",
    "        \n",
    "        spam_email_txt_split = spam_email_body.split()\n",
    "        spam_email_txt_split = list(Counter(spam_email_txt_split).keys())\n",
    "        spam_split_list.append(spam_email_txt_split)\n",
    "        \n",
    "        subject_spam_split = subject_spam.split()\n",
    "        subject_spam_split = list(Counter(subject_spam_split).keys())\n",
    "        spam_subject_split_list.append(subject_spam_split)\n",
    "        \n",
    "                \n",
    "        spam_email_txt = spam_email_txt.replace('imzabatuhan928','')\n",
    "        spam_all.append(spam_email_txt)\n",
    "        \n",
    "        spam_email_split = spam_email_txt.split()\n",
    "        spam_all_split_list.append(spam_email_split)\n",
    "        \n",
    "    df_spam = pd.DataFrame()\n",
    "    df_spam['Email'] = spam_email_list\n",
    "    df_spam['Email_All'] = spam_all\n",
    "    df_spam['Email_All_Split'] = spam_all_split_list\n",
    "    df_spam['Email_Body'] = spam_list\n",
    "    df_spam['Email_Body_Split'] = spam_split_list\n",
    "    df_spam['Email_Subject'] = spam_subject_list\n",
    "    df_spam['Email_Subject_Split'] = spam_subject_split_list\n",
    "    \n",
    "    \n",
    "    df_spam['F_Spam'] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_all = pd.concat([df_spam,df_ham])\n",
    "    \n",
    "    df_all = df_all.reset_index()\n",
    "    df_all = df_all.iloc[:,1:]\n",
    "    \n",
    "    \n",
    "    X_spam = df_spam.drop('F_Spam',axis=1) \n",
    "    y_spam = df_spam['F_Spam'] \n",
    "    X_train_spam, X_test_spam, y_train_spam, y_test_spam = train_test_split(X_spam, y_spam\\\n",
    "                                                                            , test_size = 0.3, random_state = 0)\n",
    "    \n",
    "    X_ham = df_ham.drop('F_Spam',axis=1) \n",
    "    y_ham = df_ham['F_Spam'] \n",
    "    X_train_ham, X_test_ham, y_train_ham, y_test_ham = train_test_split(X_ham, y_ham, test_size = 0.3\\\n",
    "                                                                        , random_state = 0)\n",
    "    \n",
    "    X_train = pd.concat([X_train_spam,X_train_ham])\n",
    "    X_test  = pd.concat([X_test_spam,X_test_ham])\n",
    "    y_train = pd.concat([y_train_spam,y_train_ham])\n",
    "    y_test  = pd.concat([y_test_spam,y_test_ham])\n",
    "    \n",
    "    X_train = X_train.reset_index()\n",
    "    X_train = X_train.iloc[:,1:]\n",
    "    X_test = X_test.reset_index()\n",
    "    X_test = X_test.iloc[:,1:]    \n",
    "    y_train = y_train.reset_index()\n",
    "    y_train = y_train.iloc[:,1:]\n",
    "    y_test = y_test.reset_index()\n",
    "    y_test = y_test.iloc[:,1:]\n",
    "    return df_all, X_train, X_test, y_train, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Based on Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Probiblities(X,Y,Delete_Words):\n",
    "    \n",
    "    X['F_Spam'] = Y\n",
    "    \n",
    "    #SPAM Mails\n",
    "    \n",
    "    Df_Spam = X[X['F_Spam']==1] \n",
    "    \n",
    "    #get all words\n",
    "    \n",
    "    Spam_Email_Body = \" \".join(Df_Spam['Email_Body'])\n",
    "    Spam_Email_Subject = \" \".join(Df_Spam['Email_Subject'])\n",
    "\n",
    "    #Get list of all words\n",
    "    \n",
    "    Spam_Email_Body_List = Spam_Email_Body.split()\n",
    "    Spam_Email_Subject_List = Spam_Email_Subject.split()\n",
    "    \n",
    "    Spam_Email_Body_List = remove_numbers(Spam_Email_Body_List)\n",
    "    Spam_Email_Subject_List = remove_numbers(Spam_Email_Subject_List)\n",
    "\n",
    "    #Get unique list of words and its counts \n",
    "    \n",
    "    Spam_Email_Body_List_Unique = list(Counter(Spam_Email_Body_List).keys())\n",
    "    Spam_Email_Subject_List_Unique = list(Counter(Spam_Email_Subject_List).keys())\n",
    "    \n",
    "    Spam_Email_Body_List_Count = list(Counter(Spam_Email_Body_List).values())\n",
    "    Spam_Email_Subject_List_Count = list(Counter(Spam_Email_Subject_List).values())\n",
    "    \n",
    "    #Get words and its counts to DataFrame\n",
    "    \n",
    "    Df_Body_Words_Spam = pd.DataFrame()\n",
    "    Df_Subject_Words_Spam = pd.DataFrame()\n",
    "    \n",
    "    Df_Body_Words_Spam['Words'] = Spam_Email_Body_List_Unique\n",
    "    Df_Body_Words_Spam['Spam_Count'] = Spam_Email_Body_List_Count\n",
    "    \n",
    "    Df_Subject_Words_Spam['Words'] = Spam_Email_Subject_List_Unique\n",
    "    Df_Subject_Words_Spam['Spam_Count'] = Spam_Email_Subject_List_Count\n",
    "    \n",
    "    #HAM Mails --------------- --------------- --------------- --------------- --------------- ---------------\n",
    "     \n",
    "    Df_Ham  = X[X['F_Spam']==0]\n",
    "    \n",
    "    #get all words\n",
    "    \n",
    "    Ham_Email_Body = \" \".join(Df_Ham['Email_Body'])\n",
    "    Ham_Email_Subject = \" \".join(Df_Ham['Email_Subject'])\n",
    "    \n",
    "    #Get list of all words\n",
    "    \n",
    "    Ham_Email_Body_List = Ham_Email_Body.split()\n",
    "    Ham_Email_Subject_List = Ham_Email_Subject.split()\n",
    "\n",
    "    Ham_Email_Body_List = remove_numbers(Ham_Email_Body_List)\n",
    "    Ham_Email_Subject_List = remove_numbers(Ham_Email_Subject_List)\n",
    "\n",
    "    #Get unique list of words and its counts \n",
    "    \n",
    "    Ham_Email_Body_List_Unique = list(Counter(Ham_Email_Body_List).keys())\n",
    "    Ham_Email_Subject_List_Unique = list(Counter(Ham_Email_Subject_List).keys())\n",
    "    \n",
    "    Ham_Email_Body_List_Count = list(Counter(Ham_Email_Body_List).values())\n",
    "    Ham_Email_Subject_List_Count = list(Counter(Ham_Email_Subject_List).values())\n",
    "    \n",
    "    Df_Body_Words_Ham = pd.DataFrame()\n",
    "    Df_Subject_Words_Ham = pd.DataFrame()\n",
    "        \n",
    "    Df_Body_Words_Ham['Words'] = Ham_Email_Body_List_Unique\n",
    "    Df_Body_Words_Ham['Ham_Count'] = Ham_Email_Body_List_Count\n",
    "    \n",
    "    Df_Subject_Words_Ham['Words'] = Ham_Email_Subject_List_Unique\n",
    "    Df_Subject_Words_Ham['Ham_Count'] = Ham_Email_Subject_List_Count\n",
    "\n",
    "    # JOIN TWO DFs\n",
    "    \n",
    "    Number_of_Spam_Email = len(Df_Spam)\n",
    "    Number_of_Ham_Email = len(Df_Ham)\n",
    "    Totatl_Email = Number_of_Spam_Email+Number_of_Ham_Email\n",
    "    P_Spam = Number_of_Spam_Email/Totatl_Email\n",
    "    P_Ham = Number_of_Ham_Email /Totatl_Email\n",
    "    \n",
    "    Df_Subject = Df_Subject_Words_Ham.merge(Df_Subject_Words_Spam, how='outer',on='Words')\n",
    "    Df_Subject.fillna(0,inplace=True)\n",
    "    Df_Subject['Total_Count'] = Df_Subject[['Ham_Count','Spam_Count']].sum(axis=1)\n",
    "    Df_Subject = Df_Subject.sort_values('Total_Count', ascending=False)\n",
    "    Df_Subject = Df_Subject.reset_index()\n",
    "    Df_Subject = Df_Subject.iloc[:,1:]\n",
    "    \n",
    "    #------------------------------------------\n",
    "    Df_Body = Df_Body_Words_Ham.merge(Df_Body_Words_Spam, how='outer',on='Words')\n",
    "    Df_Body.fillna(0,inplace=True)\n",
    "    Df_Body['Total_Count'] = Df_Body[['Ham_Count','Spam_Count']].sum(axis=1)\n",
    "    Df_Body = Df_Body.sort_values('Total_Count', ascending=False)\n",
    "    Df_Body = Df_Body.reset_index()\n",
    "    Df_Body = Df_Body.iloc[:,1:]\n",
    "    \n",
    "    #------------------------------------------\n",
    "    Df_Email = Df_Body.merge(Df_Subject, how='outer',on='Words')\n",
    "    Df_Email.fillna(0,inplace=True)\n",
    "    \n",
    "    Df_Email['Ham_Count'] = Df_Email[['Ham_Count_x','Ham_Count_y']].sum(axis=1)\n",
    "    Df_Email['Spam_Count'] = Df_Email[['Spam_Count_x','Spam_Count_y']].sum(axis=1)\n",
    "    Df_Email['Total_Count'] = Df_Email[['Total_Count_x','Total_Count_y']].sum(axis=1)\n",
    "    \n",
    "    Df_Email['P(Word|Spam)'] = Df_Email['Spam_Count']/Df_Email['Spam_Count'].sum(axis=0)\n",
    "    Df_Email['P(Word|Ham)']  = Df_Email['Ham_Count']/Df_Email['Ham_Count'].sum(axis=0)\n",
    "    \n",
    "    Df_Email[Df_Email['P(Word|Spam)']==0] = 0.1\n",
    "    Df_Email[Df_Email['P(Word|Ham)']==0]  = 0.01\n",
    "    \n",
    "    dict = {'Words': ['enron', 'transmission', 'energy', 'powerplants', 'intercontinental', 'financial', 'workshop',\n",
    "                      'retantion', 'article', 'fw', 'fyi', 'junaury', 'feburuary', 'march', 'april', 'may',\n",
    "                      'june', 'july', 'august', 'september','october', 'november', 'december', 'pipe' ,'pipeline',\n",
    "                     'xls','attached','txt','click','parchuse'],\n",
    "            'Ham_Count': [ 100, 100, 100, 100, 100, 100, 100,\n",
    "                      100, 100, 100, 100, 100 ,100, 100, 100, 100,\n",
    "                      100, 100, 100, 100,100,100, 100, 100 ,100,100,100,100,1,1],\n",
    "            'Spam_Count': [ 1, 1, 1, 1, 1, 1, 1,\n",
    "                      1, 1, 1, 1, 1 ,1, 1, 1, 1,\n",
    "                      1, 1, 1, 1,1,1, 1, 1 ,1,1,1,1,100,100],\n",
    "            'Total_Count': [ 101, 101, 101, 101, 101, 101, 101,\n",
    "                      101, 101, 101, 101, 101 ,101, 101, 101, 101,\n",
    "                      101, 101, 101, 101, 101, 101, 101, 101 ,101,101,101,101,101,101],\n",
    "            'P(Word|Spam)': [ 1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam,\n",
    "                      1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam ,1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam,\n",
    "                      1*P_Spam, 1*P_Spam, 1*P_Spam, 1*P_Spam,1*P_Spam,1*P_Spam, 1*P_Spam, 1*P_Spam ,1*P_Spam\n",
    "                             , 1*P_Spam ,1*P_Spam,1*P_Spam,1000*P_Spam,1000*P_Spam],\n",
    "            'P(Word|Ham)': [ 1000*P_Ham, 1000*P_Ham, 1000*P_Ham, 1000*P_Ham, 1000*P_Ham, 1000*P_Ham, 1000*P_Ham,\n",
    "                      100*P_Ham, 100*P_Ham, 100*P_Ham, 1000*P_Ham, 1000*P_Ham ,1000*P_Ham, 1000*P_Ham, 1000*P_Ham, 1000*P_Ham,\n",
    "                      1000*P_Ham, 1000*P_Ham, 1000*P_Ham, 1000*P_Ham,1000*P_Ham,1000*P_Ham, 1000*P_Ham, 1000*P_Ham ,1000*P_Ham\n",
    "                            , 1000*P_Ham ,1000*P_Ham,1000*P_Ham,1*P_Ham,1*P_Ham]\n",
    "            }\n",
    "    \n",
    "    dict_df = pd.DataFrame(dict)\n",
    "    \n",
    "    Df_Email['P(Word|Spam)'] = Df_Email['P(Word|Spam)']*1000\n",
    "    Df_Email['P(Word|Ham)'] = Df_Email['P(Word|Ham)']*1000\n",
    "    \n",
    "    \n",
    "    Df_Email.drop(['Spam_Count_x','Spam_Count_y','Ham_Count_x','Ham_Count_y','Total_Count_x','Total_Count_y'\\\n",
    "                  ],axis=1,inplace=True)\n",
    "    \n",
    "    Df_Email = Df_Email[~Df_Email['Words'].isin(Delete_Words)]\n",
    "    Df_Email = Df_Email[Df_Email['Words'].str.len()>2]\n",
    "    \n",
    "    Df_Email = pd.concat([Df_Email,dict_df])\n",
    "   \n",
    "    Df_Email = Df_Email.sort_values('Total_Count', ascending=False)\n",
    "    Df_Email = Df_Email.reset_index()\n",
    "    Df_Email = Df_Email.iloc[:,1:]\n",
    "    \n",
    "    return Df_Body, Df_Subject, Df_Email, P_Spam, P_Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fit_Naive_Bayes_Model(X,Y,DF,P_Spam,P_Ham,Delete_Words):  \n",
    "    \n",
    "    Spam_Probs = []\n",
    "    spam_count = DF['Spam_Count'].sum()\n",
    "    ham_count = DF['Ham_Count'].sum()\n",
    "    count_normalizer = spam_count/ham_count\n",
    "    \n",
    "    for index, row in X.iterrows():\n",
    "        spam_list_of_in = []\n",
    "        spam_list_of_not_in = []\n",
    "        ham_list_of_not_in = []\n",
    "        ham_list_of_in = []\n",
    "        \n",
    "        \n",
    "        row['Email_All_Split'] = list(set(row['Email_All_Split']) - set(Delete_Words))\n",
    "        row['Email_All_Split'] = remove_length(row['Email_All_Split'])\n",
    "        row['Email_All_Split'] = remove_numbers(row['Email_All_Split'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        spam_length_probs, ham_length_probs = length_probs(row['Email_All_Split'],count_normalizer,60,0.9)\n",
    "        spam_is_english_probs, ham_is_english_probs = is_english_probs(row['Email_All_Split'],count_normalizer\\\n",
    "                                                                        ,60,0.85,0.55)\n",
    "        \n",
    "        spam_list = list(DF[DF['Words'].isin(row['Email_All_Split'])]['P(Word|Spam)'])\n",
    "        spam_list.extend(spam_length_probs)\n",
    "        spam_list.extend(spam_is_english_probs)\n",
    "\n",
    "        P_Spam_M = np.prod(spam_list) * P_Spam\n",
    "        \n",
    "        ham_list = list(DF[DF['Words'].isin(row['Email_All_Split'])]['P(Word|Ham)'])\n",
    "        ham_list.extend(ham_length_probs)\n",
    "        ham_list.extend(ham_is_english_probs)\n",
    "        P_Ham_M  = np.prod(ham_list) * P_Ham\n",
    "\n",
    "        \n",
    "        P_Spam_M_Norm = P_Spam_M / (P_Spam_M + P_Ham_M)\n",
    "        Spam_Probs.append(P_Spam_M_Norm)      \n",
    "\n",
    "    X['Real'] = Y\n",
    "    X['Pred'] = Spam_Probs\n",
    "    X['1'] = 1\n",
    "    X['0'] = 0\n",
    "    X['Pred'].fillna(0,inplace=True)\n",
    "    \n",
    "    return X[['Real','Pred','1','0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_all_6, X_train_6, X_test_6, y_train_6, y_test_6 = get_email_list(\"enron6/ham\", \"enron6/spam\")\n",
    "Df_Body_6, Df_Subject_6, Df_Email_6, P_Spam_6, P_Ham_6 = Get_Probiblities(X_train_6, y_train_6, Delete_Words)\n",
    "\n",
    "df_all_1, X_train_1, X_test_1, y_train_1, y_test_1 = get_email_list(\"enron1/ham\", \"enron1/spam\")\n",
    "Df_Body_1, Df_Subject_1, Df_Email_1, P_Spam_1, P_Ham_1 = Get_Probiblities(X_train_1, y_train_1, Delete_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Email_All</th>\n",
       "      <th>Email_All_Split</th>\n",
       "      <th>Email_Body</th>\n",
       "      <th>Email_Body_Split</th>\n",
       "      <th>Email_Subject</th>\n",
       "      <th>Email_Subject_Split</th>\n",
       "      <th>Real</th>\n",
       "      <th>Pred</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>4792.2005-07-02.GP.spam.txt</td>\n",
       "      <td>healthy reproductive analysis\\ni just wanted ...</td>\n",
       "      <td>[really, reproductive, man, good, also, counte...</td>\n",
       "      <td>\\ni just wanted to write and thank you for spu...</td>\n",
       "      <td>[i, just, wanted, to, write, and, thank, you, ...</td>\n",
       "      <td>healthy reproductive analysis</td>\n",
       "      <td>[healthy, reproductive, analysis]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0560.2000-03-06.farmer.ham.txt</td>\n",
       "      <td>manager coaching program\\nd   fyi \\n         ...</td>\n",
       "      <td>[call, , , com, contact, week, program, staff,...</td>\n",
       "      <td>\\nd   fyi \\n                      forwarded by...</td>\n",
       "      <td>[d, fyi, forwarded, by, brenda, f, herod, hou,...</td>\n",
       "      <td>manager coaching program</td>\n",
       "      <td>[manager, coaching, program]</td>\n",
       "      <td>0</td>\n",
       "      <td>3.517466e-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Email  \\\n",
       "861     4792.2005-07-02.GP.spam.txt   \n",
       "861  0560.2000-03-06.farmer.ham.txt   \n",
       "\n",
       "                                             Email_All  \\\n",
       "861   healthy reproductive analysis\\ni just wanted ...   \n",
       "861   manager coaching program\\nd   fyi \\n         ...   \n",
       "\n",
       "                                       Email_All_Split  \\\n",
       "861  [really, reproductive, man, good, also, counte...   \n",
       "861  [call, , , com, contact, week, program, staff,...   \n",
       "\n",
       "                                            Email_Body  \\\n",
       "861  \\ni just wanted to write and thank you for spu...   \n",
       "861  \\nd   fyi \\n                      forwarded by...   \n",
       "\n",
       "                                      Email_Body_Split  \\\n",
       "861  [i, just, wanted, to, write, and, thank, you, ...   \n",
       "861  [d, fyi, forwarded, by, brenda, f, herod, hou,...   \n",
       "\n",
       "                     Email_Subject                Email_Subject_Split  Real  \\\n",
       "861  healthy reproductive analysis  [healthy, reproductive, analysis]     1   \n",
       "861       manager coaching program       [manager, coaching, program]     0   \n",
       "\n",
       "             Pred  1  0  \n",
       "861  1.000000e+00  1  0  \n",
       "861  3.517466e-28  1  0  "
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_1.loc[861,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Ham_Count</th>\n",
       "      <th>Spam_Count</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>P(Word|Spam)</th>\n",
       "      <th>P(Word|Ham)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>668.0</td>\n",
       "      <td>6090.0</td>\n",
       "      <td>6758.0</td>\n",
       "      <td>4.239559</td>\n",
       "      <td>1.260159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>3818.0</td>\n",
       "      <td>5794.0</td>\n",
       "      <td>2.657904</td>\n",
       "      <td>3.727655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>2912.0</td>\n",
       "      <td>4502.0</td>\n",
       "      <td>2.027192</td>\n",
       "      <td>2.999479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>information</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>4466.0</td>\n",
       "      <td>2.314006</td>\n",
       "      <td>2.154343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>statements</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3974.0</td>\n",
       "      <td>3990.0</td>\n",
       "      <td>2.766504</td>\n",
       "      <td>0.030183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Words  Ham_Count  Spam_Count  Total_Count  P(Word|Spam)  P(Word|Ham)\n",
       "0      company      668.0      6090.0       6758.0      4.239559     1.260159\n",
       "1          com     1976.0      3818.0       5794.0      2.657904     3.727655\n",
       "2       please     1590.0      2912.0       4502.0      2.027192     2.999479\n",
       "3  information     1142.0      3324.0       4466.0      2.314006     2.154343\n",
       "4   statements       16.0      3974.0       3990.0      2.766504     0.030183"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_Email_6.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For--> Train: Enron-1 , Test: Enron-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For--> Train: Enron-1 , Test: Enron-1\n",
      "True Positive: 0.95\n",
      "True Negative: 0.96\n",
      "False Negative: 0.05\n",
      "False Positive: 0.04\n",
      "Precision: 0.96\n",
      "Recall: 0.95\n",
      "F 1: 0.95\n"
     ]
    }
   ],
   "source": [
    "DF = Fit_Naive_Bayes_Model(X_test_1,y_test_1,Df_Email_1,P_Spam_1,P_Ham_1,Delete_Words)\n",
    "True_Positive =  (DF[(DF['Pred'] >= 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "False_Negative =  (DF[(DF['Pred'] < 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "True_Negative = (DF[(DF['Pred'] < 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "False_Positive = (DF[(DF['Pred'] >= 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "print(\"For--> Train: Enron-1 , Test: Enron-1\")\n",
    "Precision = True_Positive/(True_Positive+False_Positive)\n",
    "Recall = True_Positive/(True_Positive+False_Negative)\n",
    "F_1 = (2*Precision*Recall)/ (Precision + Recall)\n",
    "print(\"True Positive: %0.2f\"%True_Positive)\n",
    "print(\"True Negative: %0.2f\"%True_Negative)\n",
    "print(\"False Negative: %0.2f\"%False_Negative)\n",
    "print(\"False Positive: %0.2f\"%False_Positive)\n",
    "print(\"Precision: %0.2f\"%Precision)\n",
    "print(\"Recall: %0.2f\"%Recall)\n",
    "print(\"F 1: %0.2f\"%F_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For--> Train: Enron-6 , Test: Enron-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For--> Train: Enron-6 , Test: Enron-6\n",
      "True Positive: 0.91\n",
      "True Negative: 0.97\n",
      "False Negative: 0.09\n",
      "False Positive: 0.03\n",
      "Precision: 0.97\n",
      "Recall: 0.91\n",
      "F 1: 0.94\n"
     ]
    }
   ],
   "source": [
    "DF = Fit_Naive_Bayes_Model(X_test_6,y_test_6,Df_Email_6,P_Spam_6,P_Ham_6,Delete_Words)\n",
    "True_Positive =  (DF[(DF['Pred'] >= 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "False_Negative =  (DF[(DF['Pred'] < 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "True_Negative = (DF[(DF['Pred'] < 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "False_Positive = (DF[(DF['Pred'] >= 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "print(\"For--> Train: Enron-6 , Test: Enron-6\")\n",
    "Precision = True_Positive/(True_Positive+False_Positive)\n",
    "Recall = True_Positive/(True_Positive+False_Negative)\n",
    "F_1 = (2*Precision*Recall)/ (Precision + Recall)\n",
    "print(\"True Positive: %0.2f\"%True_Positive)\n",
    "print(\"True Negative: %0.2f\"%True_Negative)\n",
    "print(\"False Negative: %0.2f\"%False_Negative)\n",
    "print(\"False Positive: %0.2f\"%False_Positive)\n",
    "print(\"Precision: %0.2f\"%Precision)\n",
    "print(\"Recall: %0.2f\"%Recall)\n",
    "print(\"F 1: %0.2f\"%F_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For--> Train: Enron-1 , Test: Enron-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For--> Train: Enron-1 , Test: Enron-6\n",
      "True Positive: 0.96\n",
      "True Negative: 0.91\n",
      "False Negative: 0.04\n",
      "False Positive: 0.09\n",
      "Precision: 0.92\n",
      "Recall: 0.96\n",
      "F 1: 0.94\n"
     ]
    }
   ],
   "source": [
    "DF = Fit_Naive_Bayes_Model(X_test_6,y_test_6,Df_Email_1,P_Spam_1,P_Ham_1,Delete_Words)\n",
    "True_Positive =  (DF[(DF['Pred'] >= 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "False_Negative =  (DF[(DF['Pred'] < 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "True_Negative = (DF[(DF['Pred'] < 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "False_Positive = (DF[(DF['Pred'] >= 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "print(\"For--> Train: Enron-1 , Test: Enron-6\")\n",
    "Precision = True_Positive/(True_Positive+False_Positive)\n",
    "Recall = True_Positive/(True_Positive+False_Negative)\n",
    "F_1 = (2*Precision*Recall)/ (Precision + Recall)\n",
    "print(\"True Positive: %0.2f\"%True_Positive)\n",
    "print(\"True Negative: %0.2f\"%True_Negative)\n",
    "print(\"False Negative: %0.2f\"%False_Negative)\n",
    "print(\"False Positive: %0.2f\"%False_Positive)\n",
    "print(\"Precision: %0.2f\"%Precision)\n",
    "print(\"Recall: %0.2f\"%Recall)\n",
    "print(\"F 1: %0.2f\"%F_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For--> Train: Enron-6 , Test: Enron-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For--> Train: Enron-6 , Test: Enron-1\n",
      "True Positive: 0.87\n",
      "True Negative: 0.97\n",
      "False Negative: 0.13\n",
      "False Positive: 0.03\n",
      "Precision: 0.96\n",
      "Recall: 0.87\n",
      "F 1: 0.91\n"
     ]
    }
   ],
   "source": [
    "DF = Fit_Naive_Bayes_Model(X_test_1,y_test_1,Df_Email_6,P_Spam_6,P_Ham_6,Delete_Words)\n",
    "True_Positive =  (DF[(DF['Pred'] >= 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "False_Negative =  (DF[(DF['Pred'] < 0.5) & (DF['Real']==1)]['1'].sum()/DF[DF['Real'] >= 0.5]['1'].sum())\n",
    "True_Negative = (DF[(DF['Pred'] < 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "False_Positive = (DF[(DF['Pred'] >= 0.5) & (DF['Real']==0)]['1'].sum()/DF[DF['Real'] < 0.5]['1'].sum())\n",
    "print(\"For--> Train: Enron-6 , Test: Enron-1\")\n",
    "Precision = True_Positive/(True_Positive+False_Positive)\n",
    "Recall = True_Positive/(True_Positive+False_Negative)\n",
    "F_1 = (2*Precision*Recall)/ (Precision + Recall)\n",
    "print(\"True Positive: %0.2f\"%True_Positive)\n",
    "print(\"True Negative: %0.2f\"%True_Negative)\n",
    "print(\"False Negative: %0.2f\"%False_Negative)\n",
    "print(\"False Positive: %0.2f\"%False_Positive)\n",
    "print(\"Precision: %0.2f\"%Precision)\n",
    "print(\"Recall: %0.2f\"%Recall)\n",
    "print(\"F 1: %0.2f\"%F_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
